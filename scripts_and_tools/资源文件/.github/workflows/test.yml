name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # 每天深夜运行完整测试
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - unit
        - integration
        - performance
        - e2e
        - smoke
      environment:
        description: 'Test environment'
        required: true
        default: 'ci'
        type: choice
        options:
        - ci
        - staging
        - production

env:
  PYTHONPATH: ${{ github.workspace }}
  TEST_ENVIRONMENT: ci
  PYTEST_TIMEOUT: 300

jobs:
  # 代码质量检查
  code-quality:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy bandit safety
        pip install -r requirements.txt
        
    - name: Code formatting check
      run: |
        black --check --diff src/ tests/
        isort --check-only --diff src/ tests/
        
    - name: Linting
      run: |
        flake8 src/ tests/ --max-line-length=120 --ignore=E203,W503
        
    - name: Type checking
      run: |
        mypy src/poe2build/ --ignore-missing-imports
        
    - name: Security check
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        safety check --json --output safety-report.json || true
        
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # 单元测试
  unit-tests:
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-html pytest-xdist pytest-mock pytest-asyncio pytest-timeout
        
    - name: Run unit tests
      env:
        TEST_MODE: fast
      run: |
        pytest -m "unit" \
          --tb=short \
          --cov=src/poe2build \
          --cov-report=html:test_reports/coverage_unit \
          --cov-report=xml:test_reports/coverage_unit.xml \
          --cov-report=term-missing \
          --html=test_reports/unit_tests.html \
          --junit-xml=test_reports/unit_tests.xml \
          -v
          
    - name: Upload unit test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results-py${{ matrix.python-version }}
        path: |
          test_reports/unit_tests.html
          test_reports/unit_tests.xml
          test_reports/coverage_unit*

  # 集成测试
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-html pytest-xdist pytest-mock pytest-asyncio pytest-timeout
        pip install redis
        
    - name: Run integration tests
      env:
        TEST_MODE: full
        REDIS_URL: redis://localhost:6379/1
        CACHE_BACKEND: redis
      run: |
        pytest -m "integration" \
          --tb=short \
          --cov=src/poe2build \
          --cov-report=html:test_reports/coverage_integration \
          --cov-report=xml:test_reports/coverage_integration.xml \
          --html=test_reports/integration_tests.html \
          --junit-xml=test_reports/integration_tests.xml \
          --timeout=600 \
          -v
          
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          test_reports/integration_tests.html
          test_reports/integration_tests.xml
          test_reports/coverage_integration*

  # 性能测试
  performance-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.event_name == 'schedule' || github.event.inputs.test_type == 'performance' || github.event.inputs.test_type == 'all'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-html pytest-benchmark pytest-timeout psutil
        
    - name: Run performance tests
      env:
        TEST_MODE: stress
        TEST_ENVIRONMENT: performance
      run: |
        pytest -m "performance" \
          --tb=short \
          --html=test_reports/performance_tests.html \
          --junit-xml=test_reports/performance_tests.xml \
          --benchmark-only \
          --benchmark-json=test_reports/benchmark.json \
          --timeout=1800 \
          -v
          
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          test_reports/performance_tests.html
          test_reports/performance_tests.xml
          test_reports/benchmark.json

  # 端到端测试
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: github.event_name == 'schedule' || github.event.inputs.test_type == 'e2e' || github.event.inputs.test_type == 'all'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-html pytest-timeout
        
    - name: Run E2E tests
      env:
        TEST_MODE: full
        TEST_ENVIRONMENT: e2e
        # 在E2E测试中可能需要真实的API密钥
        # POE2_API_KEY: ${{ secrets.POE2_API_KEY }}
      run: |
        pytest -m "e2e" \
          --tb=short \
          --html=test_reports/e2e_tests.html \
          --junit-xml=test_reports/e2e_tests.xml \
          --timeout=900 \
          -v
          
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: |
          test_reports/e2e_tests.html
          test_reports/e2e_tests.xml

  # 烟雾测试（快速验证）
  smoke-tests:
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'smoke'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-html
        
    - name: Run smoke tests
      env:
        TEST_MODE: smoke
      run: |
        pytest -m "smoke or (unit and not slow)" \
          --tb=line \
          --html=test_reports/smoke_tests.html \
          --junit-xml=test_reports/smoke_tests.xml \
          --timeout=60 \
          -v
          
    - name: Upload smoke test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: smoke-test-results
        path: |
          test_reports/smoke_tests.html
          test_reports/smoke_tests.xml

  # 测试覆盖率汇总
  coverage-report:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: always() && (needs.unit-tests.result == 'success' || needs.integration-tests.result == 'success')
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install coverage[toml] codecov
        
    - name: Download unit test coverage
      uses: actions/download-artifact@v3
      with:
        name: unit-test-results-py3.11
        path: coverage_unit/
      continue-on-error: true
        
    - name: Download integration test coverage
      uses: actions/download-artifact@v3
      with:
        name: integration-test-results
        path: coverage_integration/
      continue-on-error: true
      
    - name: Combine coverage reports
      run: |
        coverage combine coverage_unit/coverage_unit.xml coverage_integration/coverage_integration.xml || true
        coverage report --show-missing || true
        coverage html -d test_reports/coverage_combined || true
        coverage xml -o test_reports/coverage_combined.xml || true
        
    - name: Upload combined coverage
      uses: actions/upload-artifact@v3
      with:
        name: combined-coverage-report
        path: test_reports/coverage_combined*
        
    - name: Upload to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: test_reports/coverage_combined.xml
        flags: unittests,integration
        name: codecov-umbrella
        fail_ci_if_error: false

  # 测试结果汇总和通知
  test-summary:
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, integration-tests, performance-tests, e2e-tests, coverage-report]
    if: always()
    
    steps:
    - name: Generate test summary
      run: |
        echo "## 测试执行摘要" >> $GITHUB_STEP_SUMMARY
        echo "| 测试类型 | 状态 |" >> $GITHUB_STEP_SUMMARY
        echo "|---------|------|" >> $GITHUB_STEP_SUMMARY
        echo "| 代码质量 | ${{ needs.code-quality.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| 单元测试 | ${{ needs.unit-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| 集成测试 | ${{ needs.integration-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| 性能测试 | ${{ needs.performance-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| E2E测试 | ${{ needs.e2e-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| 覆盖率报告 | ${{ needs.coverage-report.result }} |" >> $GITHUB_STEP_SUMMARY
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 构建信息" >> $GITHUB_STEP_SUMMARY
        echo "- **分支**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **提交**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- **触发方式**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **执行时间**: $(date)" >> $GITHUB_STEP_SUMMARY
        
    - name: Check overall test status
      run: |
        if [[ "${{ needs.code-quality.result }}" != "success" ]]; then
          echo "代码质量检查失败"
          exit 1
        fi
        
        if [[ "${{ needs.unit-tests.result }}" != "success" ]]; then
          echo "单元测试失败"
          exit 1
        fi
        
        # 集成测试和其他测试失败时给出警告但不阻塞
        if [[ "${{ needs.integration-tests.result }}" != "success" && "${{ needs.integration-tests.result }}" != "skipped" ]]; then
          echo "::warning::集成测试失败或被跳过"
        fi
        
        echo "主要测试通过 ✅"